# music_genre_recognition
Comparasion of the efficiency of music genre recognition algorithms
Вхідними даними  є датасет FMA-medium, який складається з 25000 пісень довжиною по 30 секунд і одним із 16 жанрів, розподіл кількості пісень по жанрах незбалансований. Також до датасету входить csv документ tracks.csv, в якому лежать всі дані про пісні, з яких були використані лише назва пісні, яка дорівнює індексу запису в файлі, top genre, тобто основний жанр пісні, приналежність пісні до датасету subset (в цьому файлі міститься інформація про всі пісні, що є в датасетах FMA, таких як small, medium i large) та колонка split, яка вказує належить трек до навчальної чи тренувальної вибірки.  Пісні розміщені по 156 папках названих числами від 0 до 155, назви пісень дорівнюють їхнім індексам в csv файлі, в кожній папці лежать пісні індекс яких в діапазоні від n*1000 до (n+1)*1000, де n – номер в назві папки, тобто наприклад в нульовій папці лежать пісні з індексом від 0 до 1000 включно.
#	Обчислення характеристик музики
	Для проведення класифікації потрібно представити аудіозаписи у вигляді набору атрибутів, які чисельно характеризують аудіозапис. Цих атрибутів є доволі багато, тому я виберу декілька основних: mel-frequency cepstral coefficients(mfcc), chroma energy normalized(chroma cens), tonal centroid features(tonnetz), spectral contrast, spectral centroid, spectral bandwidth, spectral rolloff, root mean squad energy(rmse), zero crossing rate(zcr). 
	Для представлення аудіозаписів в вигляді атрибутів використовується функція features_write(), яка працює наступним чином:
•	В датафрейм загружається файл tracks.csv
•	Відкидаються записи зі значенням large колонки subsets, оскільки ці пісні не входять в наш датасет.
•	В окремий масив зберігаються індекси пісень, які дорівнюють їх назві
•	Створюється датафрейм з перерахованими вище атрибутами пісень
•	Для кожного індекса в списку за допомогою бібліотеки librosa відкривається аудіозапис, імя якого складається з індекса, доповненого при потребі нулями зпереду до довжини 6 символів, а папка в якій лежить цей файл має назву що складається з перших 3 цифр назви аудіозапису.
•	Для завантаженого аудіозапису обраховуються всі атрибути, в датафрейм записується середнє значення кожного атрибуту, оскільки ці атрибути вираховуються для кожного моменту часу. Якщо аудіозапис пошкоджений або не існує, що рідко, але трапляється, записуємо Null замість атрибутів.
•	Після проходження всіх аудіозаписів, датафрейм з атрибутами записується в csv файл features_short.csv
3.3.	Попередня обробка та розбиття на тестові та тренувальні дані
Після обчислення атрибутів аудіозаписів підготуємо дані для навчання та тестування класифікаторів. В підготовку входить нормалізація даних, видалення даних що містять Null та поділ датасету на тренувальну та тестувальну вибірки.
Для цього викличемо функцію data_prepare(), яка працює наступним чином:
•	В датафрейми загружаються файли tracks.csv з інформацією про пісні такою як основний жанр, та features_short.csv з атрибутами цих пісень.
•	На екран виводиться список жанрів
•	З датасету tracks видаляються записи, в яких subset має значення large
•	В змінні y_train і y_test записується серія, в якої індекс рівний назві пісні, а значенням є жанр пісні, ця серія видобувається з датафрейму tracks, в y_train записуються пісні, які будуть належати до тренувальної вибірки, а в y_test – до тестувальної
•	В змінні X_train i X_test записуються датафрейми що містять атрибути пісень з датафрейму features_short, в X_train записуються атрибути пісень, індекси яких містяться в наборі y_train, X_test – в y_test.
•	З X_train і X_test видаляються записи що містять NaN
•	З y_train і y_test видаляються записи про пісні, які були видалені з X_train і X_test
•	Виконується нормалізація даних X_train і X_test з використанням StandartScaler, що обчислює нові значення за формулою на рисунку 10:
•	Функція повертає датафрейми X_test i X_train та серії y_test i y_train, які в наступному розділі будуть використовуватися для навчання і тестування моделей класифікації

# ЗАСТОСУВАННЯ ТА ПОРІВНЯННЯ ЕФЕКТИВНОСТІ МЕТОДІВ АНАЛІЗУ
Застосування заявлених методів для побудови моделей класифікації	
Для того щоб натренувати моделі всіх методів класифікації після того як обчислили характеристики пісень викличемо функцію genre_classifier(). Вона працює наступним чином:
•	викликає функцію data_prepare(), для того щоб підготувати дані, цей процес описаний в розділі 3.3., ця функція повертає тренувальні та навчальні дані X_train, X_test, y_train, y_test;
•	створюємо словник, в якому назві кожного методу класифікації буде відповідати екземпляр класифікатора з відповідними параметрами, детальніше про кожен метод буде розписано в наступному підрозділі;
•	створюємо словники в які будемо записувати точність кожного методу;
•	для кожного класифікатора в словнику тренуємо цей  класифікатор використовуючи тренувальні дані X_train, y_train, де Х_train – атрибути музики, y_train – її клас;
•	для кожного натренованого класифікатора тестуємо його та будуємо матрицю неточностей та звіт, в якому описані міри точності моделі;
•	зберігаємо точність і час тренування кожної моделі в словники;
•	зберігаємо натреновану модель в файл;
•	після того як всі моделі будуть натреновані виводимо на екран їх точність та час виконання для порівняння.

#Опис побудови кожної моделі класифікації
1.	Логістична регресія	
Модель класифікатора логістичної регресії створюється за допомогою методу LogisticRegression бібліотеки sklearn для Python. Я використовував параметри за замовчуванням, основними з яких є вирішувач (solver), який за замовченням встановлений lbfgs, який підходить для класифікації наборів даних з великою кількістю класів, зворотня сила регуляризації С, яка за замовчанням рівна 1, та штраф (penalty) l2, який є єдиним підтримуваним для вирішувача lbfgs.
2.	Random Forest
Модель класифікатора Random Forest створюється за допомогою методу RandomForestClassifier бібліотеки sklearn для Python. Критерій поділу дерев стоїть за замовчанням gini, максимальну глибину max_depth я встановив як 5, кількість дерев  n_estimators рівна 10, кількість атрибутів з яких на кожному кроці побудови дерева обирається найкращий max_features рівна 5, оскільки всього кількість атрибутів дорівнює 9, тому щоб був елемент випадковості кількість атрибутів встановлена приблизно на половину від максимальної.
3.	K-найближчих сусідів
Модель класифікатора K-найближчих сусідів створюється за допомогою методу KNeighborsClassifier бібліотеки sklearn для Python. Метрика відстані(metric) за замовчуванням встановлена як Minkowski з p=2, тобто це еквіваленто евклідовій відстані, алгоритм(algoritm) встановлений як auto, тобто вибирається найбільш підходящий алгоритм на основі вхідних даних, можливі алгоритми BallTree, який використовує кулькове дерево, KDTree який використовує червоно-чорне дерево та brute, що є брутфорс алгоритмом, тобто алгоритмом, що просто перебирає всі можливі комбінації. Кількість сусідніх точок(k_neighbors), на основі відстані до яких відбувається віднесення до одного з класів, я встановив як 200.
4.	SVC
Для порівняння було створено 4 моделі класифікатора SCV, а саме: 3 моделі створені за допомогою методу SVC бібліотеки sklearn для Python - модель SVCrbf з ядром(kernel) rbf, модель SVCpoly1 з ядром(kernel) poly і степенем полінома(degree) за замовчуванням рівним 3, linSVC1 з ядром(kernel) linear, та модель створена за допомогою методу LinearSVC тієї ж бібліотеки.
5.	Дерева рішень
Для порівняння було створено 4 моделі класифікатора дерева рішень за допомогою методу DecisionTreeClassifier бібліотеки sklearn для Python. У моделі DT-5_gini критерій розбивки(criterion) має значення gini, а глибина дерева (max_depth) рівна 5, у моделі DTFull_gini такий самий критерій розбивки, але глибина дерева необмежена, у моделі DT-5_entropy критерій розбивки entropy і глибина 5, у моделі DTFull_entropy критерій розбивки entropy і глибина необмежена. 4 моделі були необхідні щоб порівняти чи перенавчається модель дерева класифікації на великій глибині дерева і який критерій розбивки ефективніший.
6.	MLP
Було побудовано дві моделі MLP з використанням методу MLPClassifier бібліотеки sklearn для Python. В обох моделях функція активації прихованого шару встановлена за замовчанням relu -  f(x) = max(0,x), вирішувач для оптимізації за замовченням adam, який працює на основі стохаїстичного градієнта і добре працює з великими наборами даних, але повільніше з малими, максимальну кількість ітерацій я встановив рівну 2000. Модель MLP1 має розмір прихованого шару (кількість нейронів в ітому шарі) рівний 100, тобто є один прихований шар з кількістю нейронів 100. Модель MLP2 має розмір прихованого шару рівний (200, 50), тобто перший прихований шар містить 200 нейронів, а другий – 50.
7.	 QDA
Модель класифікатора QDA створюється за допомогою методу QuadraticDiscriminantAnalysis бібліотеки sklearn для Python. Були використані параметри за замовчуванням, а саме пріоритетність класів priors рівна None, тобто вона виводиться з навчальних даних, reg_param, який впорядковує оцінки коваріації для кожного класу рівний 0.

# Порівняння отриманих результатів
На рисунках нижче наведено точність(accuracy) кожної моделі та час тренування моделі.
 
 ![image](https://user-images.githubusercontent.com/54076963/136072714-f522f347-4552-4d5c-bac5-865840e90963.png)
![image](https://user-images.githubusercontent.com/54076963/136072860-d3646a4e-6b51-4733-9bb6-419accdfb8b9.png)
	З цих двох рисунків можна зробити висновок, що найточнішими моделями були MLP1 SCVrbf 59.3% та 59.7% відповідно. Також ці дві моделі є одними з найповільніших з часом 180.9 та 46.3 секунд. Далі буде детальніше проаналізовано результати деяких моделей.
	На рисунках зображено матрицю неточностей моделі логістичної регресії та звіт з різними показниками ефективності для кожного класу і взагальному для моделі.

 ![image](https://user-images.githubusercontent.com/54076963/136072948-c3d7b6d6-0816-4237-a566-67c4e52ccf79.png)
![image](https://user-images.githubusercontent.com/54076963/136073052-402e6417-ac80-46ab-97ff-5e69f6af71af.png)
	В першу чергу нам потрібно звертати увагу на метрику precision, яка вказує на відношення кількості пісень яким присвоєний даний жанр до всієї кількості пісень яким присвоєно цей жанр, тому що навіть якщо пісні якогось жанру будуть класифікуватися правильно, але пісням всіх інших жанрів також буде присвоюватися цей жанр, то класифікатор явно не можна назвати успішним. В цієї моделі вона замітно менша за значення метрики accuracy, що є показником того, що пісні деяких жанрів класифікуються добре, але багато пісень інших жанрів помилково відносять до деяких з класів що визначаються правильно. Метрика recall  також важлива, бо вона вказує на класи, які складно класифікувати, показуючи відношення правильно віднесених до жанра пісень до загальної кількості пісень цього жанру. 
	Тепер проаналізуємо дві найбільш вдалі моделі, якщо орієнтуватися в першу чергу на значення precision,  recall та f1-score – середньозважене значення цих двох метрик. Найкращі значення цих метрик, а також метрики accuracy має MLP1, тобто багатошаровий персептрон з одним прихованим шаром і 100 нейронів в цьому шарі. Зразу за ним йде модель класифікатора метода опорних векторів з ядром rbf SVCrbf, в якої на 5% нижчий показник  precision, але на 1% вищий показник recall та на 0.5% вищий показник accuracy. Багатошаровий персептрон з двома прихованими шарами по 200 та 50 нейронів також показує непогані показники, всі з яких на декілька процентів нижчі ніж в моделі з одним шаром, тому цю модель ми розглядати не будем, і її матрицю неточностей та звіт класифікації можна знайти в додатках, як і для всіх інших методів, що не були розглянуті детально.
  матриця неточностей MLP1
 ![image](https://user-images.githubusercontent.com/54076963/136073172-719a78a0-68fa-42db-9313-214e62132a36.png)
 звіт з якості класифікації MLP1
![image](https://user-images.githubusercontent.com/54076963/136073192-db13109d-a2ba-4ffb-a30c-5f28de68fc10.png)
матриця неточностей SVCrbf
![image](https://user-images.githubusercontent.com/54076963/136073226-4497ff8e-6bbb-438e-8fb6-ee41fb2af488.png)
звіт з якості класифікації SVCrbf
![image](https://user-images.githubusercontent.com/54076963/136073399-11383b34-cc71-4e44-b532-c44753f6469c.png)


Як можна побачити з цих двох матриць неточностей і звітів обидва методи класифікації мають одні і ті ж проблеми, а саме:
•	Експериментальну, хіп-хоп, інструментальну, джаз і рок часто помилково відносять до жанру електонної музики.
•	Електронну музику в свою чергу доволі часто помилково відносять до експериментальної, фольку і року
•	Експериментальну, хіп-хоп і soul-rnb помилково відносять до року
•	Деякі жанри через малу кількість навчальних прикладів взагалі не ідентифікуються, а саме spoken, soul-rnb, джаз, international, easy listening і блюз
Також модель SVCrbf має проблеми з хіп хопом, який на відміну від моделі MLP1 взагалі не розпізнається, хоча є доволі багато навчальних прикладів (оскільки кількість тестових прикладів співвідноситься до кількості навчальних прикладів, а тестових прикладів для хіп-хопу є 120). Інші навчальні моделі мають приблизно ті  ж проблеми з деякими незначними відмінностями і в загальному нижчою точністю.
Зважаючи на описані вище проблеми, найкращим методом класифікації аудіо по жанрах з досліджуваних мною є багатошаровий персептрон (MLP) з одним прихованим шаром і 100 нейронів в цьому шарі. Також близькими по результату були багатошаровий персептрон з 2 шарами по 200 та 50 нейронів та класифікатор метода опорних векторів з ядром rbf. Проте MLP є найповільнішим методом з розглянутих, а SVC йде зразу після MLP. Далі я коротко порівняю моделі одного метода з різними параметрами.
Дерево рішень показало найкращі показники з обмеженням глибини 5 рівнів, на великій глибині точність accuracy та recall починають зменшуватися через перенавчання, проте precision збільшується на 2%. Точність і інші показники окрім часу в моделей з критерієм розподілу gini та entropy приблизно однакові, однак дерева з критерієм gini будуються в 1.9 раз швидше ніж з gini.
Класифікатор метода опорних векторів (SVC) показує найкращі показники з ядром rbf, з лінійним ядром всі його показники всередньому на 3-4% гірші за показники з ядром rbf, проте швидкість одної з реалізацій на четверту частину більша. Метод з ядром poly має такий ж precision як з лінійним ядром, проте  всі інші показники включаючи швидкість гірші, accuracy i recall на 3-4%, швидкість в 2-3 рази.
Найшвидшим алгоритмом виявився метод квадратичних дискримінантів QDA, при цьому він має точність accuracy кращу за більшість методів що виконуються за приблизно такий ж час, винятками є Random Forest i kNN, хоча в них показники precision на 6-8% нижчі ніж в QDA. Також подібну швидкість має дерево прийняття рішень, проте accuracy та percision в них нижча на 1-2% та 8-9% відповідно, останнє особливо критично.

# Застосування для визначення жанру випадкових пісень
Щоб перевірити як на практиці буде визначатися жанр пісні за допомогою натренованих класифікаторів я написав функцію genre_define, яка приймає два аргумента – шлях до пісні та метод класифікації, за замовчуванням будуть використовуватися всі методи.
Були перевірені такі пісні: Moonlight Sonata Бетховена, жанр якої – класична музика, Gorillaz - Feel Good Inc, основний жанр якої вважається electronic, The Prodigy – Mindfields також з жанром electronic та Nirvana - Smells Like Teen Spirit з жанром рок. Результати на рисунку
 ![Uploading image.png…]()

Жанр Moonlight Sonata та Gorillaz - Feel Good Inc був присвоєний правильно, але пісні  Nirvana - Smells Like Teen Spirit був помилково присвоєний жанр електронна музика, а The Prodigy – Mindfields – експериментальна музика, і якщо електронна музика тісно повязана з експериментальною музикою і помилку можна зрозуміти, то чому виникла помилка з роком пояснити складніше. Я спробував викликати алгоритм ще для декількох пісень жанру рок, але в результаті завжди отримував або експериментальну або електронну музику. Цю проблему я мабуть можу пояснити різноманітністю видів року, які часто значно відрізняються один від одного. 

В майбутньому планується реалізувати згорткову нейронну мережу(CNN), оскільки її ефективність може бути вищою за реалізовані мною алгоритми.

